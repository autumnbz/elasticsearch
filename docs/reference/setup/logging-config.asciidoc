[[logging]]
=== 日志配置

Elasticsearch 使用 https://logging.apache.org/log4j/2.x/[Log4j 2] 记录日志。
 Log4j 2 可通过 log4j2.properties 配置。 Elasticsearch 暴露了三个属性，`${sys:es.logs.base_path}` 、
`${sys:es.logs.cluster_name}` 和 `${sys:es.logs.node_name}` （如果通过 `node.name` 显式设置节点名称） 可在配置文件中指定并决定日志文件位置。
`${sys:es.logs.base_path}` 属性解析为日志目录，`${sys:es.logs.cluster_name}` 属性解析为集群名（默认配置中作为日志文件名前缀），`${sys:es.logs.node_name}` 属性解析为节点名（如果显式设置节点名）。

举个例子，如果你的日志目录（`path.logs` ）是 `/var/log/elasticsearch` ，集群名是 `production` ，那么 `${sys:es.logs.base_path}` 将解析为 `/var/log/elasticsearch` ，
 `${sys:es.logs.base_path}${sys:file.separator}${sys:es.logs.cluster_name}.log` 将解析为 `/var/log/elasticsearch/production.log` 。

[source,properties]
--------------------------------------------------
appender.rolling.type = RollingFile <1>
appender.rolling.name = rolling
appender.rolling.fileName = ${sys:es.logs.base_path}${sys:file.separator}${sys:es.logs.cluster_name}.log <2>
appender.rolling.layout.type = PatternLayout
appender.rolling.layout.pattern = [%d{ISO8601}][%-5p][%-25c{1.}] %marker%.-10000m%n
appender.rolling.filePattern = ${sys:es.logs.base_path}${sys:file.separator}${sys:es.logs.cluster_name}-%d{yyyy-MM-dd}-%i.log.gz <3>
appender.rolling.policies.type = Policies
appender.rolling.policies.time.type = TimeBasedTriggeringPolicy <4>
appender.rolling.policies.time.interval = 1 <5>
appender.rolling.policies.time.modulate = true <6>
appender.rolling.policies.size.type = SizeBasedTriggeringPolicy <7>
appender.rolling.policies.size.size = 256MB <8>
appender.rolling.strategy.type = DefaultRolloverStrategy
appender.rolling.strategy.fileIndex = nomax
appender.rolling.strategy.action.type = Delete <9>
appender.rolling.strategy.action.basepath = ${sys:es.logs.base_path}
appender.rolling.strategy.action.condition.type = IfFileName <10>
appender.rolling.strategy.action.condition.glob = ${sys:es.logs.cluster_name}-* <11>
appender.rolling.strategy.action.condition.nested_condition.type = IfAccumulatedFileSize <12>
appender.rolling.strategy.action.condition.nested_condition.exceeds = 2GB <13>
--------------------------------------------------

<1> 配置 `RollingFile` 追加方式
<2> 日志名为 `/var/log/elasticsearch/production.log`
<3> 滚动日志为 `/var/log/elasticsearch/production-yyyy-MM-dd-i.log`；每个滚动日志将被压缩，并且 `i` 会增加
<4> 使用基于时间的滚动策略
<5> 滚动日志天数
<6> 日边界对其滚动（与每 24 小时滚动相反）
<7> 使用基于尺寸的滚动策略
<8> 每 256 MB 滚动
<9> 滚动日志时执行删除操作
<10> 只删除匹配文件模式的日志
<11> 该模式仅用于删除主日志
<12> 只有累积了太多压缩日志时才能删除
<13> 压缩日志大小条件为 2 GB

NOTE: Log4j 的解析配置会被无关的空白符混淆；如果你复制粘贴此页面上的任何 Log4j 设置，或者输入任何通用 Log4j，请确认修剪开头和结尾空格。

注意，你可以将 `appender.rolling.filePattern` 中的 `.gz` 替换为 `.zip` ，这样可以
使用 zip 格式压缩滚动日志。 如果你删除 `.gz` ，那么日志将不会被压缩，因为它们是滚动的。

如果你想保留一段时间的日志文件，你可以使用一个带有删除操作的滚动策略。

[source,properties]
--------------------------------------------------
appender.rolling.strategy.type = DefaultRolloverStrategy <1>
appender.rolling.strategy.action.type = Delete <2>
appender.rolling.strategy.action.basepath = ${sys:es.logs.base_path} <3>
appender.rolling.strategy.action.condition.type = IfFileName <4>
appender.rolling.strategy.action.condition.glob = ${sys:es.logs.cluster_name}-* <5>
appender.rolling.strategy.action.condition.nested_condition.type = IfLastModified <6>
appender.rolling.strategy.action.condition.nested_condition.age = 7D <7>
--------------------------------------------------

<1> 配置 `DefaultRolloverStrategy`
<2> 配置 `Delete` 操作处理滚动
<3> Elasticsearch 日志基本路径
<4> 滚动处理应用条件
<5> 删除匹配 `${sys:es.logs.cluster_name}-*` 路径的滚动日志文件；
    这只需要删除滚动 Elasticsearch 日志，而不是删除过期和慢日志
<6> 适用于匹配 glob 文件的嵌套条件
<7> 保留七天日志

可以加载多个配置文件（在这种情况下，它们将被合并），只要这些配置文件被命名为 `log4j2.properties` ，同时它们的祖先目录为 Elasticsearch 配置
目录；这对于暴露附加日志的插件非常有用。日志部分包含 java 包及其相应的日志级别。
appender 部分包含日志地址。如何自定义日志及追加支持的所有信息请参考
 http://logging.apache.org/log4j/2.x/manual/configuration.html[Log4j
文档] 。

[float]
[[configuring-logging-levels]]
=== 配置日志等级

有四种方式配置日志等级，每种方式有其适应场景。

1. 通过命令行： `-E <name of logging hierarchy>=<level>` （例如 `-E logger.org.elasticsearch.transport=trace` ）
   这对单节点临时调试问题（例如启动或开发阶段问题）是最合适的。
2. 通过 `elasticsearch.yml` : `<name of logging hierarchy>: <level>` （例如 `logger.org.elasticsearch.transport: trace` ）。
   这对非命令行（例如通过服务）启动 Elasticsearch 的临时调试问题， 或者想以更固定方式调整日志级别是最合适的。
3. 通过 <<cluster-logger,集群设置>>:
+
--
[source,js]
-------------------------------
PUT /_cluster/settings
{
  "transient": {
    "<name of logging hierarchy>": "<level>"
  }
}
-------------------------------
// NOTCONSOLE

例如：

[source,js]
-------------------------------
PUT /_cluster/settings
{
  "transient": {
    "logger.org.elasticsearch.transport": "trace"
  }
}
-------------------------------
// CONSOLE

当你需要动态调整运行集群的日志级别时，这是最合适的。

--
4. 通过 `log4j2.properties`:
+
--
[source,properties]
--------------------------------------------------
logger.<unique_identifier>.name = <name of logging hierarchy>
logger.<unique_identifier>.level = <level>
--------------------------------------------------

例如：

[source,properties]
--------------------------------------------------
logger.transport.name = org.elasticsearch.transport
logger.transport.level = trace
--------------------------------------------------

当您需要对日志进行细粒度控制时（例如，你想发送日志到其他文件，或者管理不同日志；这种场景比较罕见），这是最合适的。
--

[float]
[[deprecation-logging]]
=== 弃用日志

除了常规日志，Elasticsearch 允许你启用日志记录已弃用的操作。 例如，这可以让你尽早决定是否需要在将来迁移某些功能。
弃用日志默认在 WARN 级别启用，该级别下所有弃用日志消息将被收集。

[source,properties]
--------------------------------------------------
logger.deprecation.level = warn
--------------------------------------------------

这将在日志目录创建一个日滚动弃用日志文件。定期检查此文件，特别是当你打算升级到新主版本。

默认弃用日志配置设置为滚动策略，日志在 1 GB 之后滚动并压缩，并最多保留五个日志
文件（四个滚动日志和当前活动日志）。

你可以在 `config/log4j2.properties` 文件设置弃用日志级别为 `error` 来禁止它。
