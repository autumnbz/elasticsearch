[[docs-delete-by-query]]
== Delete By Query API

 `_delete_by_query`  最简单的使用场景是删除匹配到的每一个文档。以下是 API：

[source,js]
--------------------------------------------------
POST twitter/_delete_by_query
{
  "query": { <1>
    "match": {
      "message": "some message"
    }
  }
}
--------------------------------------------------
// CONSOLE
// TEST[setup:big_twitter]

<1> query 必须作为值传递给 `query` 键，与 <<search-search,Search API>> 方式相同。
你同样可以使用 `q` 参数作为 search api。

将返回类似以下内容：

[source,js]
--------------------------------------------------
{
  "took" : 147,
  "timed_out": false,
  "deleted": 119,
  "batches": 1,
  "version_conflicts": 0,
  "noops": 0,
  "retries": {
    "bulk": 0,
    "search": 0
  },
  "throttled_millis": 0,
  "requests_per_second": -1.0,
  "throttled_until_millis": 0,
  "total": 119,
  "failures" : [ ]
}
--------------------------------------------------
// TESTRESPONSE[s/"took" : 147/"took" : "$body.took"/]

`_delete_by_query` 在启动时获取索引快照，并使用 `internal` 版本删除它发现的内容。
这意味着使用快照执行删除请求期间文档更改后你会得到版本冲突。当匹配版本号的文档已删除。

NOTE: 因为 `internal` 版本号不支持 0 作为有效版本数，不能使用 `_delete_by_query` 删除版本号等于零的文档，同时请求将失败。

执行 `_delete_by_query` 期间，会顺序执行多个搜索请求以便找到所有需要删除的匹配文档。
 每当找到一批文档，便会执行相应的批请求来删除这些文档。如果搜索或批请求被拒绝，`_delete_by_query` 会依据
 默认策略来重试拒绝的请求（直到 10 次，指数返回）。达到最大重试限制会造成 `_delete_by_query` 中止，并在响应中返回所有 `failures` 。
 已经执行的删除仍然保持。换言之就是处理不会回滚，只中止。当第一次失败导致中止后，所有失败批请求中的失败内容都会在 `failures` 元素中返回；
 因此有可能存在不少失败实体。

如果你想统计版本冲突而不是中止它们，那么可以在 url 上设置 `conflicts=proceed` 或在请求体中添加 `"conflicts": "proceed"` 。

回到 API 格式，你可以限制 `_delete_by_query` 为单一类型。这只会删除 `twitter` 索引中的 `tweet` 文档。

[source,js]
--------------------------------------------------
POST twitter/_doc/_delete_by_query?conflicts=proceed
{
  "query": {
    "match_all": {}
  }
}
--------------------------------------------------
// CONSOLE
// TEST[setup:twitter]

同样可以一次删除多个索引和多个类型，就像这个 search API 一样：

[source,js]
--------------------------------------------------
POST twitter,blog/tweet,post/_delete_by_query
{
  "query": {
    "match_all": {}
  }
}
--------------------------------------------------
// CONSOLE
// TEST[s/^/PUT twitter\nPUT blog\n/]

如果你提供 `routing` 那么路由会复制到 scroll query ，将处理过程限制在与路由值匹配的分片上：

[source,js]
--------------------------------------------------
POST twitter/_delete_by_query?routing=1
{
  "query": {
    "range" : {
        "age" : {
           "gte" : 10
        }
    }
  }
}
--------------------------------------------------
// CONSOLE
// TEST[setup:twitter]

`_delete_by_query` 默认批量滚动数为 1000。你可以使用 `scroll_size` URL 参数改变这个批量大小：

[source,js]
--------------------------------------------------
POST twitter/_delete_by_query?scroll_size=5000
{
  "query": {
    "term": {
      "user": "kimchy"
    }
  }
}
--------------------------------------------------
// CONSOLE
// TEST[setup:twitter]


[float]
=== URL 参数

除了类似 `pretty` 的标准参数，Delete By Query API 同样支持 `refresh` 、 `wait_for_completion` 、 `wait_for_active_shards` 和 `timeout` 。

发送 `refresh` 会使得一旦请求完成后 refresh delete by query 所涉及的分片。
这与 Delete API 的 `refresh` 参数不同，该参数只 refresh 接受删除请求的分片。

如果请求包含 `wait_for_completion=false` ，那么 Elasticsearch 会执行一些预检校验、启动请求、然后返回
一个可用于 <<docs-delete-by-query-task-api,Tasks APIs>> 来取消或获取任务转态任务。
Elasticsearch 会将以 `.tasks/task/${taskId}` 创建该任务的文档记录。你可以根据需要保留或删除它。
当你完成它以后，请删除它以便 Elasticsearch 可以回收使用的空间。

`wait_for_active_shards` 控制了执行请求前需要有多少活动分片。
更多细节请参考 <<index-wait-for-active-shards,here>> 。`timeout` 控制每次写请求时分片不可用到可用的等待时间。
两者都能在 <<docs-bulk,Bulk API>> 中正确工作。

`requests_per_second` 可以设置为任何正数（`1.4` 、 `6` 、 `1000` 等），用来限制
`_delete_by_query` 每批删除操作等待时间的速率。可以设置 `requests_per_second` 为 `-1` 来禁止节流。

节流是在每批操作之间等待以便 `_delete_by_query` 内部使用的 scroll 可以将 padding 纳入超时时间。
padding 是由批大小除以 `requests_per_second` 再减去写耗时得来的。
默认批大小是 `1000` ，如果 `requests_per_second` 为 `500` ：

[source,txt]
--------------------------------------------------
target_time = 1000 / 500 per second = 2 seconds
wait_time = target_time - write_time = 2 seconds - .5 seconds = 1.5 seconds
--------------------------------------------------

因为单 `_bulk` 批请求会造成 Elasticsearch 创建很多请求，然后在启动下一组前等待。这是 "bursty" 而不是 "smooth" 。
默认为 `-1` 。

[float]
=== Response body

//////////////////////////

[source,js]
--------------------------------------------------
POST /twitter/_delete_by_query
{
  "query": { <1>
    "match": {
      "message": "some message"
    }
  }
}
--------------------------------------------------
// CONSOLE
// TEST[setup:big_twitter]

//////////////////////////

类似如下 JSON 响应：

[source,js]
--------------------------------------------------
{
  "took" : 147,
  "timed_out": false,
  "total": 119,
  "deleted": 119,
  "batches": 1,
  "version_conflicts": 0,
  "noops": 0,
  "retries": {
    "bulk": 0,
    "search": 0
  },
  "throttled_millis": 0,
  "requests_per_second": -1.0,
  "throttled_until_millis": 0,
  "failures" : [ ]
}
--------------------------------------------------
// TESTRESPONSE[s/: [0-9]+/: $body.$_path/]

`took`::

整个操作从开始到结束的毫秒数。

`timed_out`::

如果在执行 delete by query 期间有任何超时则此标志为 `true` 。

`total`::

成功处理的文档总数。

`deleted`::

成功删除的文档总数。

`batches`::

delete by query 拉取滚动响应的数量。

`version_conflicts`::

delete by query 版本冲突数量。

`noops`::

 delete by query 中该字段常常等于零。它只存在 delete by query 、update by query 和 reindex APIs 中，并以相同结果返回。

`retries`::

delete by query 尝试的重试次数。`bulk` 是批行为重试数，`search` 是搜索行为重试数。

`throttled_millis`::

请求休眠的毫秒数，与 `requests_per_second` 一致。

`requests_per_second`::

执行 delete by query 期间每秒有效执行请求数。

`throttled_until_millis`::

delete by query 响应中该字段应该等于零。它只意味着在使用 <<docs-delete-by-query-task-api, Task API>> 时，
为了匹配 `requests_per_second` 再次执行节流请求的下一次时间（自 epoch 毫秒数）。

`failures`::

所有索引失败的数组。如果非空则代表请求因为失败中止。请参考 `conflicts` 了解如果阻止中止操作中的版本冲突。


[float]
[[docs-delete-by-query-task-api]]
=== 与 Task API 协作

你可以通过 <<tasks,Task API>> 获取运行 delete-by-query 请求期间的状态。

[source,js]
--------------------------------------------------
GET _tasks?detailed=true&actions=*/delete/byquery
--------------------------------------------------
// CONSOLE

得到类似如下响应：

[source,js]
--------------------------------------------------
{
  "nodes" : {
    "r1A2WoRbTwKZ516z6NEs5A" : {
      "name" : "r1A2WoR",
      "transport_address" : "127.0.0.1:9300",
      "host" : "127.0.0.1",
      "ip" : "127.0.0.1:9300",
      "attributes" : {
        "testattr" : "test",
        "portsfile" : "true"
      },
      "tasks" : {
        "r1A2WoRbTwKZ516z6NEs5A:36619" : {
          "node" : "r1A2WoRbTwKZ516z6NEs5A",
          "id" : 36619,
          "type" : "transport",
          "action" : "indices:data/write/delete/byquery",
          "status" : {    <1>
            "total" : 6154,
            "updated" : 0,
            "created" : 0,
            "deleted" : 3500,
            "batches" : 36,
            "version_conflicts" : 0,
            "noops" : 0,
            "retries": 0,
            "throttled_millis": 0
          },
          "description" : ""
        }
      }
    }
  }
}
--------------------------------------------------
// NOTCONSOLE
// We can't test tasks output

<1> 这个对象包含实际状态。它就类似一个包含重要 `total` 字段的 json 响应。`total` 是操作重建索引期望执行的操作总数。
你可以通过添加 `updated` 、 `created` 和 `deleted` 字段来估计。当这些值的总和等于 `total` 字段时请求会结束。

With the task id you can look up the task directly:
你可以直接以 task id 查看任务：

[source,js]
--------------------------------------------------
GET /_tasks/taskId:1
--------------------------------------------------
// CONSOLE
// TEST[catch:missing]

这个 API 的有点是它集成了 `wait_for_completion=false` 并透明地返回已完成任务的状态。
如果任务已完成且设置了 `wait_for_completion=false` ，那么任务会以 `results` 或 `error` 字段返回。
`wait_for_completion=false` 这个功能的成本是在 `.tasks/task/${taskId}` 创建 `wait_for_completion=false` 。
是否删除这个文档由你决定。


[float]
[[docs-delete-by-query-cancel-task-api]]
=== 与 Cancel Task API 协作

任何 Delete By Query 可以使用 <<tasks,Task Cancel API>> 取消：

[source,js]
--------------------------------------------------
POST _tasks/task_id:1/_cancel
--------------------------------------------------
// CONSOLE

`task_id` 可以使用上文提到的 tasks API 查找：

取消操作应该会很快发生但仍可能消耗几秒钟。上文提到的 task status API 仍将继续，直到被唤醒取消。

[float]
[[docs-delete-by-query-rethrottle]]
=== Rethrottling

可以在运行 delete by query 时使用 `_rethrottle` API 改变 `requests_per_second` 值：

[source,js]
--------------------------------------------------
POST _delete_by_query/task_id:1/_rethrottle?requests_per_second=-1
--------------------------------------------------
// CONSOLE

`task_id` 可以使用上文提到的 tasks API 查找：

正如在 `_delete_by_query` API 设置的一样，`requests_per_second` 可以设置为 `-1` 禁止节流，也可以是控制节流的任意正数，例如 `1.7` 或 `12` 。
加速查询 rethrotting 会立即生效，但是降低查询 rethrotting 会在当前批处理完成后生效。
这样可以阻止 scroll 超时。

[float]
[[docs-delete-by-query-slice]]
=== Slicing

Delete-by-query 支持 <<sliced-scroll>> 来并行删除操作。并行可以提高效率并提供一个便捷途径
将请求分解成更小的部分。

[float]
[[docs-delete-by-query-manual-slice]]
==== 手动 slicing

提供 slice id 和每个请求的切片数量来对 delete-by-query 手动切片：

[source,js]
----------------------------------------------------------------
POST twitter/_delete_by_query
{
  "slice": {
    "id": 0,
    "max": 2
  },
  "query": {
    "range": {
      "likes": {
        "lt": 10
      }
    }
  }
}
POST twitter/_delete_by_query
{
  "slice": {
    "id": 1,
    "max": 2
  },
  "query": {
    "range": {
      "likes": {
        "lt": 10
      }
    }
  }
}
----------------------------------------------------------------
// CONSOLE
// TEST[setup:big_twitter]

可以通过这种方式验证：

[source,js]
----------------------------------------------------------------
GET _refresh
POST twitter/_search?size=0&filter_path=hits.total
{
  "query": {
    "range": {
      "likes": {
        "lt": 10
      }
    }
  }
}
----------------------------------------------------------------
// CONSOLE
// TEST[continued]

结果中合理的 `total` 类似这样：

[source,js]
----------------------------------------------------------------
{
  "hits": {
    "total": 0
  }
}
----------------------------------------------------------------
// TESTRESPONSE

[float]
[[docs-delete-by-query-automatic-slice]]
==== 自动 slicing

你可以使用 <<sliced-scroll>> `_uid` 让 delete-by-query 自动并行切片。
使用 `slices` 指定切片数：

[source,js]
----------------------------------------------------------------
POST twitter/_delete_by_query?refresh&slices=5
{
  "query": {
    "range": {
      "likes": {
        "lt": 10
      }
    }
  }
}
----------------------------------------------------------------
// CONSOLE
// TEST[setup:big_twitter]

可以通过这种方式验证：

[source,js]
----------------------------------------------------------------
POST twitter/_search?size=0&filter_path=hits.total
{
  "query": {
    "range": {
      "likes": {
        "lt": 10
      }
    }
  }
}
----------------------------------------------------------------
// CONSOLE
// TEST[continued]

结果中合理的 `total` 类似这样：

[source,js]
----------------------------------------------------------------
{
  "hits": {
    "total": 0
  }
}
----------------------------------------------------------------
// TESTRESPONSE

设置 `slices` 为 `auto` 会让 Elasticsearch 选择选择使用的切片数。这个设置为每个分片使用一个切片，直到上限。
如果有多个源索引，它的选择取决于最小分片数的索引。

向 `_delete_by_query` 添加 `slices` 可以自动处理以上章节的手动流程，创建子请求意味着有一些奇怪：

* 你可以在 <<docs-delete-by-query-task-api,Tasks APIs>> 查看请求，这些子请求是 `slices` 请求任务的 "child" 任务。
* 获取 `slices` 请求任务的状态只包含已完成切片的状态。
* 子请求可以单独寻址，例如取消和 rethrottling。
* `slices` 的 rethrottling 请求会按比例 rethrottle 未完成的子任务。
* `slices` 的取消请求会取消所有子请求。
* 由于 `slices` 性质，每个子请求不会均匀的获取文档。所有文档都可寻址，但是一些切片可能会大于其他切片。更大的期望切片可以有更均匀的分布。
* 带有 `requests_per_second` 和 `size` 参数的 `slices` 请求会均匀地分发至每个子请求。
结合上述提及的分布不均，你应该得出结论， `slices` 中使用 `size` 可能不会使 `size` 文档精确地被 `_delete_by_query` 。
* 每个子请求都会获得与源索引轻微不同的快照，尽管这些几乎是在同一时间进行的。

[float]
[[docs-delete-by-query-picking-slices]]
===== 选择切片数量

如果自动切片，设置 `slices` 为 `auto` 将为多数索引选择合理的切片数。如果手动切片或者优化自动切片，使用以下建议。

`slices` 数与索引分片数相等时查询性能是最高效的。如果这个数太大，（例如，500）选择一个更小的数，因为太多的 `slices` 损害性能。
设置 `slices` 高于分片数一般不会提示性能且会增加负载。

删除性能可通过切片数量线性扩展。

查询或删除性能取决于是否在重索引文档以及集群资源。
